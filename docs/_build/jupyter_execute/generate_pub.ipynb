{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is using only to generate markdown file with arXiv id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv_id = \"2307.10729\"\n",
    "# url = f\"http://export.arxiv.org/api/query?search_query=id:{arxiv_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv = [\n",
    "    \"2109.06493\",\n",
    "    \"2302.07040\",\n",
    "    \"2312.13657\",\n",
    "    \"2212.06656\",\n",
    "    \"2201.09361\",\n",
    "    \"2111.10867\",\n",
    "    \"2202.11386\",\n",
    "    \"2204.11787\",\n",
    "    \"2205.02600\",\n",
    "    \"2307.14223\",\n",
    "    \"2204.00602\",\n",
    "    \"2206.10577\",\n",
    "    \"2303.03117\",\n",
    "    \"2302.11887\",\n",
    "    \"2308.15489\",\n",
    "    \"2311.07476\",\n",
    "    \"2205.09567\",\n",
    "    \"2301.12946\",\n",
    "    \"2307.02959\",\n",
    "    \"2311.05529\",\n",
    "    \"2301.09192\",\n",
    "    \"2311.07506\",\n",
    "    \"2311.08108\",\n",
    "    \"2307.10729\",\n",
    "    \"2312.00712\",\n",
    "    \"2402.12018\",\n",
    "    \"2402.06299\",\n",
    "    \"2311.10480\",\n",
    "    \"2311.03215\",\n",
    "    \"2402.07809\",\n",
    "    \"2210.15396\",\n",
    "    \"2303.03978\",\n",
    "    \"2309.15547\",\n",
    "    \"2306.17159\",\n",
    "    \"2301.10196\",\n",
    "    \"2311.03347\",\n",
    "    \"2311.05258\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = [\n",
    "\"2212.06656\",\n",
    "\"2201.09361\",\n",
    "\"2111.10867\",\n",
    "\"2202.11386\",\n",
    "\"2204.11787\",\n",
    "\"2204.00602\",\n",
    "\"2302.11887\"\n",
    "]\n",
    "\n",
    "phy = [\"2205.09567\",\n",
    "\"2301.12946\",\n",
    "\"2311.07506\",\n",
    "\"2311.08108\",\n",
    "\"2312.00712\"\n",
    "]\n",
    "\n",
    "opt = [\"2309.15547\"]\n",
    "\n",
    "cryp = [\"2402.07809\",\n",
    "\"2210.15396\",\n",
    "\"2303.03978\"\n",
    "]\n",
    "\n",
    "error = [\"2307.02959\",\n",
    "\"2311.05529\",\n",
    "\"2301.09192\",\n",
    "\"2307.10729\"\n",
    "]\n",
    "\n",
    "algo = [\"2109.06493\",\n",
    "\"2302.07040\",\n",
    "\"2312.13657\",\n",
    "\"2205.02600\",\n",
    "\"2307.14223\",\n",
    "\"2206.10577\",\n",
    "\"2303.03117\",\n",
    "\"2308.15489\",\n",
    "\"2311.07476\",\n",
    "\"2402.12018\",\n",
    "\"2402.06299\",\n",
    "\"2311.10480\",\n",
    "\"2311.03215\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_content = '# Publications \\n\\n Ce document présente une liste de publications ayant bénéficié du programme HQI.\\n\\n  ```{important} \\n La plupart des publications sont référencées sur le portail <a href=\"https://haltools.archives-ouvertes.fr/Public/afficheRequetePubli.php?projet_anr=ANR-22-PNCQ-0002&CB_auteur=oui&CB_titre=oui&CB_DOI=oui&CB_resume=oui&langue=Francais&tri_exp=annee_publi&tri_exp2=typdoc&tri_exp3=date_publi&ordre_aff=TA&CB_rubriqueDiv=oui&Fen=Aff&css=../css/VisuCondense.css\">HAL HQI-R&D Support</a> et <a href=\"https://haltools.archives-ouvertes.fr/Public/afficheRequetePubli.php?projet_anr=ANR-22-PNCQ-0001&CB_auteur=oui&CB_titre=oui&CB_DOI=oui&CB_resume=oui&langue=Francais&tri_exp=annee_publi&tri_exp2=typdoc&tri_exp3=date_publi&ordre_aff=TA&CB_rubriqueDiv=oui&Fen=Aff&css=../css/VisuCondense.css\">HAL HQI-Acquisition</a>. Cependant, certaines publications étant mal référencées, vous trouverez ici les preprints ArXiV.\\n ``` \\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre: Formal Methods for Quantum Programs: A Survey\n",
      "Date de publication: 14/09/2021\n",
      "Auteur(s):\n",
      "- Christophe Chareton\n",
      "- Sébastien Bardin\n",
      "- Dongho Lee\n",
      "- Benoît Valiron\n",
      "- Renaud Vilmart\n",
      "- Zhaowei Xu\n",
      "Résumé:   While recent progress in quantum hardware open the door for significant\n",
      "speedup in certain key areas (cryptography, biology, chemistry, optimization,\n",
      "machine learning, etc), quantum algorithms are still hard to implement right,\n",
      "and the validation of such quantum programs is achallenge. Moreover, importing\n",
      "the testing and debugging practices at use in classical programming is\n",
      "extremely difficult in the quantum case, due to the destructive aspect of\n",
      "quantum measurement. As an alternative strategy, formal methods are prone to\n",
      "play a decisive role in the emerging field of quantum software. Recent works\n",
      "initiate solutions for problems occurring at every stage of the development\n",
      "process: high-level program design, implementation, compilation, etc. We review\n",
      "the induced challenges for an efficient use of formal methods in quantum\n",
      "computing and the current most promising research directions.\n",
      "\n",
      "Titre: Optimal Hadamard gate count for Clifford$+T$ synthesis of Pauli  rotations sequences\n",
      "Date de publication: 14/02/2023\n",
      "Auteur(s):\n",
      "- Vivien Vandaele\n",
      "- Simon Martiel\n",
      "- Simon Perdrix\n",
      "- Christophe Vuillot\n",
      "Résumé:   The Clifford$+T$ gate set is commonly used to perform universal quantum\n",
      "computation. In such setup the $T$ gate is typically much more expensive to\n",
      "implement in a fault-tolerant way than Clifford gates. To improve the\n",
      "feasibility of fault-tolerant quantum computing it is then crucial to minimize\n",
      "the number of $T$ gates. Many algorithms, yielding effective results, have been\n",
      "designed to address this problem. It has been demonstrated that performing a\n",
      "pre-processing step consisting of reducing the number of Hadamard gates in the\n",
      "circuit can help to exploit the full potential of these algorithms and thereby\n",
      "lead to a substantial $T$-count reduction. Moreover, minimizing the number of\n",
      "Hadamard gates also restrains the number of additional qubits and operations\n",
      "resulting from the gadgetization of Hadamard gates, a procedure used by some\n",
      "compilers to further reduce the number of $T$ gates. In this work we tackle the\n",
      "Hadamard gate reduction problem, and propose an algorithm for synthesizing a\n",
      "sequence of $\\pi/4$ Pauli rotations with a minimal number of Hadamard gates.\n",
      "Based on this result, we present an algorithm which optimally minimizes the\n",
      "number of Hadamard gates lying between the first and the last $T$ gate of the\n",
      "circuit.\n",
      "\n",
      "Titre: On the Hardness of Analyzing Quantum Programs Quantitatively\n",
      "Date de publication: 21/12/2023\n",
      "Auteur(s):\n",
      "- Martin Avanzini\n",
      "- Georg Moser\n",
      "- Romain Péchoux\n",
      "- Simon Perdrix\n",
      "Résumé:   In this paper, we study quantitative properties of quantum programs.\n",
      "Properties of interest include (positive) almost-sure termination, expected\n",
      "runtime or expected cost, that is, for example, the expected number of\n",
      "applications of a given quantum gate, etc. After studying the completeness of\n",
      "these problems in the arithmetical hierarchy over the Clifford+T fragment of\n",
      "quantum mechanics, we express these problems using a variation of a quantum\n",
      "pre-expectation transformer, a weakest precondition based technique that allows\n",
      "to symbolically compute these quantitative properties. Under a smooth\n",
      "restriction-a restriction to polynomials of bounded degree over a real closed\n",
      "field-we show that the quantitative problem, which consists in finding an\n",
      "upper-bound to the pre-expectation, can be decided in time double-exponential\n",
      "in the size of a program, thus providing, despite its great complexity, one of\n",
      "the first decidable results on the analysis and verification of quantum\n",
      "programs. Finally, we sketch how the latter can be transformed into an\n",
      "efficient synthesis method.\n",
      "\n",
      "Titre: A programming language characterizing quantum polynomial time\n",
      "Date de publication: 13/12/2022\n",
      "Auteur(s):\n",
      "- Emmanuel Hainry\n",
      "- Romain Péchoux\n",
      "- Mário Silva\n",
      "Résumé:   We introduce a first-order quantum programming language, named FOQ, whose\n",
      "terminating programs are reversible. We restrict FOQ to a strict and tractable\n",
      "subset, named PFOQ, of terminating programs with bounded width, that provides a\n",
      "first programming language-based characterization of the quantum complexity\n",
      "class FBQP. Finally, we present a tractable semantics-preserving algorithm\n",
      "compiling a PFOQ program to a quantum circuit of size polynomial in the number\n",
      "of input qubits.\n",
      "\n",
      "Titre: Quantum Expectation Transformers for Cost Analysis\n",
      "Date de publication: 23/01/2022\n",
      "Auteur(s):\n",
      "- Martin Avanzini\n",
      "- Georg Moser\n",
      "- Romain Péchoux\n",
      "- Simon Perdrix\n",
      "- Vladimir Zamdzhiev\n",
      "Résumé:   We introduce a new kind of expectation transformer for a mixed\n",
      "classical-quantum programming language. Our semantic approach relies on a new\n",
      "notion of a cost structure, which we introduce and which can be seen as a\n",
      "specialisation of the Kegelspitzen of Keimel and Plotkin. We show that our\n",
      "weakest precondition analysis is both sound and adequate with respect to the\n",
      "operational semantics of the language. Using the induced expectation\n",
      "transformer, we provide formal analysis methods for the expected cost analysis\n",
      "and expected value analysis of classical-quantum programs. We illustrate the\n",
      "usefulness of our techniques by computing the expected cost of several\n",
      "well-known quantum algorithms and protocols, such as coin tossing, repeat until\n",
      "success, entangled state preparation, and quantum walks.\n",
      "\n",
      "Titre: Qimaera: Type-safe (Variational) Quantum Programming in Idris\n",
      "Date de publication: 21/11/2021\n",
      "Auteur(s):\n",
      "- Liliane-Joy Dandy\n",
      "- Emmanuel Jeandel\n",
      "- Vladimir Zamdzhiev\n",
      "Résumé:   Variational Quantum Algorithms are hybrid classical-quantum algorithms where\n",
      "classical and quantum computation work in tandem to solve computational\n",
      "problems. These algorithms create interesting challenges for the design of\n",
      "suitable programming languages. In this paper we introduce Qimaera, which is a\n",
      "set of libraries for the Idris 2 programming language that enable the\n",
      "programmer to implement (variational) quantum algorithms where the full power\n",
      "of the elegant Idris language works in synchrony with quantum programming\n",
      "primitives that we introduce. The two key ingredients of Idris that make this\n",
      "possible are (1) dependent types which allow us to implement unitary (i.e.\n",
      "reversible and controllable) quantum operations; and (2) linearity which allows\n",
      "us to enforce fine-grained control over the execution of quantum operations\n",
      "that ensures compliance with the laws of quantum mechanics. We demonstrate that\n",
      "Qimaera is suitable for variational quantum programming by providing\n",
      "implementations of the two most prominent variational quantum algorithms --\n",
      "QAOA and VQE. To the best of our knowledge, this is the first implementation of\n",
      "these algorithms that has been achieved in a type-safe framework.\n",
      "\n",
      "Titre: Addition and Differentiation of ZX-diagrams\n",
      "Date de publication: 23/02/2022\n",
      "Auteur(s):\n",
      "- Emmanuel Jeandel\n",
      "- Simon Perdrix\n",
      "- Margarita Veshchezerova\n",
      "Résumé:   The ZX-calculus is a powerful framework for reasoning in quantum computing.\n",
      "It provides in particular a compact representation of matrices of interests. A\n",
      "peculiar property of the ZX-calculus is the absence of a formal sum allowing\n",
      "the linear combinations of arbitrary ZX-diagrams. The universality of the\n",
      "formalism guarantees however that for any two ZX-diagrams, the sum of their\n",
      "interpretations can be represented by a ZX-diagram. We introduce a general,\n",
      "inductive definition of the addition of ZX-diagrams, relying on the\n",
      "construction of controlled diagrams. Based on this addition technique, we\n",
      "provide an inductive differentiation of ZX-diagrams.\n",
      "  Indeed, given a ZX-diagram with variables in the description of its angles,\n",
      "one can differentiate the diagram according to one of these variables.\n",
      "Differentiation is ubiquitous in quantum mechanics and quantum computing (e.g.\n",
      "for solving optimization problems). Technically, differentiation of ZX-diagrams\n",
      "is strongly related to summation as witnessed by the product rules.\n",
      "  We also introduce an alternative, non inductive, differentiation technique\n",
      "rather based on the isolation of the variables. Finally, we apply our results\n",
      "to deduce a diagram for an Ising Hamiltonian.\n",
      "\n",
      "Titre: LOv-Calculus: A Graphical Language for Linear Optical Quantum Circuits\n",
      "Date de publication: 25/04/2022\n",
      "Auteur(s):\n",
      "- Alexandre Clément\n",
      "- Nicolas Heurtel\n",
      "- Shane Mansfield\n",
      "- Simon Perdrix\n",
      "- Benoît Valiron\n",
      "Résumé:   We introduce the LOv-calculus, a graphical language for reasoning about\n",
      "linear optical quantum circuits with so-called vacuum state auxiliary inputs.\n",
      "We present the axiomatics of the language and prove its soundness and\n",
      "completeness: two LOv-circuits represent the same quantum process if and only\n",
      "if one can be transformed into the other with the rules of the LOv-calculus. We\n",
      "give a confluent and terminating rewrite system to rewrite any\n",
      "polarisation-preserving LOv-circuit into a unique triangular normal form,\n",
      "inspired by the universal decomposition of Reck et al. (1994) for linear\n",
      "optical quantum circuits.\n",
      "\n",
      "Titre: Completeness of Sum-Over-Paths for Toffoli-Hadamard and the Dyadic  Fragments of Quantum Computation\n",
      "Date de publication: 05/05/2022\n",
      "Auteur(s):\n",
      "- Renaud Vilmart\n",
      "Résumé:   The \"Sum-Over-Paths\" formalism is a way to symbolically manipulate linear\n",
      "maps that describe quantum systems, and is a tool that is used in formal\n",
      "verification of such systems. We give here a new set of rewrite rules for the\n",
      "formalism, and show that it is complete for \"Toffoli-Hadamard\", the simplest\n",
      "approximately universal fragment of quantum mechanics. We show that the\n",
      "rewriting is terminating, but not confluent (which is expected from the\n",
      "universality of the fragment). We do so using the connection between\n",
      "Sum-over-Paths and graphical language ZH-Calculus, and also show how the\n",
      "axiomatisation translates into the latter. Finally, we show how to enrich the\n",
      "rewrite system to reach completeness for the dyadic fragments of quantum\n",
      "computation -- obtained by adding phase gates with dyadic multiples of $\\pi$ to\n",
      "the Toffoli-Hadamard gate-set -- used in particular in the Quantum Fourier\n",
      "Transform.\n",
      "\n",
      "Titre: Rewriting and Completeness of Sum-Over-Paths in Dyadic Fragments of  Quantum Computing\n",
      "Date de publication: 26/07/2023\n",
      "Auteur(s):\n",
      "- Renaud Vilmart\n",
      "Résumé:   The \"Sum-Over-Paths\" formalism is a way to symbolically manipulate linear\n",
      "maps that describe quantum systems, and is a tool that is used in formal\n",
      "verification of such systems. We give here a new set of rewrite rules for the\n",
      "formalism, and show that it is complete for \"Toffoli-Hadamard\", the simplest\n",
      "approximately universal fragment of quantum mechanics. We show that the\n",
      "rewriting is terminating, but not confluent (which is expected from the\n",
      "universality of the fragment). We do so using the connection between\n",
      "Sum-over-Paths and graphical language ZH-calculus, and also show how the\n",
      "axiomatisation translates into the latter. We provide generalisations of the\n",
      "presented rewrite rules, that can prove useful when trying to reduce terms in\n",
      "practice, and we show how to graphically make sense of these new rules. We show\n",
      "how to enrich the rewrite system to reach completeness for the dyadic fragments\n",
      "of quantum computation, used in particular in the Quantum Fourier Transform,\n",
      "and obtained by adding phase gates with dyadic multiples of $\\pi$ to the\n",
      "Toffoli-Hadamard gate-set. Finally, we show how to perform sums and\n",
      "concatenation of arbitrary terms, something which is not native in a system\n",
      "designed for analysing gate-based quantum computation, but necessary when\n",
      "considering Hamiltonian-based quantum computation.\n",
      "\n",
      "Titre: Perceval: A Software Platform for Discrete Variable Photonic Quantum  Computing\n",
      "Date de publication: 01/04/2022\n",
      "Auteur(s):\n",
      "- Nicolas Heurtel\n",
      "- Andreas Fyrillas\n",
      "- Grégoire de Gliniasty\n",
      "- Raphaël Le Bihan\n",
      "- Sébastien Malherbe\n",
      "- Marceau Pailhas\n",
      "- Eric Bertasi\n",
      "- Boris Bourdoncle\n",
      "- Pierre-Emmanuel Emeriau\n",
      "- Rawad Mezher\n",
      "- Luka Music\n",
      "- Nadia Belabas\n",
      "- Benoît Valiron\n",
      "- Pascale Senellart\n",
      "- Shane Mansfield\n",
      "- Jean Senellart\n",
      "Résumé:   We introduce Perceval, an open-source software platform for simulating and\n",
      "interfacing with discrete-variable photonic quantum computers, and describe its\n",
      "main features and components. Its Python front-end allows photonic circuits to\n",
      "be composed from basic photonic building blocks like photon sources, beam\n",
      "splitters, phase-shifters and detectors. A variety of computational back-ends\n",
      "are available and optimised for different use-cases. These use state-of-the-art\n",
      "simulation techniques covering both weak simulation, or sampling, and strong\n",
      "simulation. We give examples of Perceval in action by reproducing a variety of\n",
      "photonic experiments and simulating photonic implementations of a range of\n",
      "quantum algorithms, from Grover's and Shor's to examples of quantum machine\n",
      "learning. Perceval is intended to be a useful toolkit for experimentalists\n",
      "wishing to easily model, design, simulate, or optimise a discrete-variable\n",
      "photonic experiment, for theoreticians wishing to design algorithms and\n",
      "applications for discrete-variable photonic quantum computing platforms, and\n",
      "for application designers wishing to evaluate algorithms on available\n",
      "state-of-the-art photonic quantum computers.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m arxiv:\n\u001b[1;32m      2\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://export.arxiv.org/api/query?search_query=id:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     root \u001b[38;5;241m=\u001b[39m ET\u001b[38;5;241m.\u001b[39mfromstring(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m      5\u001b[0m     namespace \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matom\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://www.w3.org/2005/Atom\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:416\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    414\u001b[0m         conn\u001b[38;5;241m.\u001b[39mrequest_chunked(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhttplib_request_kw)\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhttplib_request_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (six\u001b[38;5;241m.\u001b[39mensure_str(k\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m headers):\n\u001b[1;32m    243\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1303\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1301\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1349\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1298\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1298\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1058\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1056\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1058\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1061\u001b[0m \n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1064\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:996\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 996\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    998\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     84\u001b[0m         sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m     \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sock\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in arxiv:\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=id:{i}\"\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    namespace = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('atom:entry', namespace)\n",
    "    \n",
    "    if entry:\n",
    "        title = entry.find('atom:title', namespace).text.replace(\"\\n\", \"\")\n",
    "        authors = entry.findall('atom:author', namespace)\n",
    "        abstract = entry.find('atom:summary', namespace).text\n",
    "        date = entry.find('atom:published', namespace).text\n",
    "        date = datetime.strptime(date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d/%m/%Y')\n",
    "\n",
    "        print(\"Titre: \"+ title)\n",
    "        print(\"Date de publication: \"+date)\n",
    "        print(\"Auteur(s):\")\n",
    "        for author in authors:\n",
    "            name = author.find('atom:name', namespace).text\n",
    "            print(\"- \"+name)\n",
    "        print(\"Résumé: \"+abstract)\n",
    "    else:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in arxiv:\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=id:{i}\"\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    namespace = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('atom:entry', namespace)\n",
    "    \n",
    "    if entry:\n",
    "        title = entry.find('atom:title', namespace).text\n",
    "        authors = entry.findall('atom:author', namespace)\n",
    "        abstract = entry.find('atom:summary', namespace).text.strip()\n",
    "        date = entry.find('atom:published', namespace).text\n",
    "        date = datetime.strptime(date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d/%m/%Y')\n",
    "        link = entry.find('atom:id', namespace).text\n",
    "\n",
    "        markdown_content += f\"## {title}\\n\\n\"\n",
    "        markdown_content += f\"**Lien de l'article :** [ArXiv]({link})\\n\\n\"\n",
    "        markdown_content += f\"**Date de publication :** {date}\\n\\n\"\n",
    "        markdown_content += \"**Auteur(s) :**\\n\"\n",
    "        for author in authors:\n",
    "            name = author.find('atom:name', namespace).text\n",
    "            markdown_content += f\"- {name}\\n\"\n",
    "        markdown_content += f\"\\n**Résumé :**\\n{abstract}\\n\\n\"\n",
    "        \n",
    "with open(\"test.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lang:\n",
    "    markdown_content = \"## Langage de programmation\\n\\n\"\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=id:{i}\"\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    namespace = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('atom:entry', namespace)\n",
    "    \n",
    "    if entry:\n",
    "        title = entry.find('atom:title', namespace).text\n",
    "        authors = entry.findall('atom:author', namespace)\n",
    "        abstract = entry.find('atom:summary', namespace).text.strip()\n",
    "        date = entry.find('atom:published', namespace).text\n",
    "        date = datetime.strptime(date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d/%m/%Y')\n",
    "        link = entry.find('atom:id', namespace).text\n",
    "\n",
    "        markdown_content += f\"### {title}\\n\\n\"\n",
    "        markdown_content += f\"**Lien de l'article :** [ArXiv]({link})\\n\\n\"\n",
    "        markdown_content += f\"**Date de publication :** {date}\\n\\n\"\n",
    "        markdown_content += \"**Auteur(s) :**\\n\"\n",
    "        for author in authors:\n",
    "            name = author.find('atom:name', namespace).text\n",
    "            markdown_content += f\"- {name}\\n\"\n",
    "        markdown_content += f\"\\n**Résumé :**\\n{abstract}\\n\\n\"\n",
    "    else:\n",
    "        print(\"No entry found\")\n",
    "        \n",
    "with open(\"test.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in phy:\n",
    "    markdown_content = \"## Problème de physique\\n\\n\"\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=id:{i}\"\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    namespace = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('atom:entry', namespace)\n",
    "    \n",
    "    if entry:\n",
    "        title = entry.find('atom:title', namespace).text\n",
    "        authors = entry.findall('atom:author', namespace)\n",
    "        abstract = entry.find('atom:summary', namespace).text.strip()\n",
    "        date = entry.find('atom:published', namespace).text\n",
    "        date = datetime.strptime(date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d/%m/%Y')\n",
    "        link = entry.find('atom:id', namespace).text\n",
    "\n",
    "        markdown_content += f\"### {title}\\n\\n\"\n",
    "        markdown_content += f\"**Lien de l'article :** [ArXiv]({link})\\n\\n\"\n",
    "        markdown_content += f\"**Date de publication :** {date}\\n\\n\"\n",
    "        markdown_content += \"**Auteur(s) :**\\n\"\n",
    "        for author in authors:\n",
    "            name = author.find('atom:name', namespace).text\n",
    "            markdown_content += f\"- {name}\\n\"\n",
    "        markdown_content += f\"\\n**Résumé :**\\n{abstract}\\n\\n\"\n",
    "        \n",
    "with open(\"test.md\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in opt:\n",
    "    markdown_content = \"## Machine learning/optimisation\\n\\n\"\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=id:{i}\"\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    namespace = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('atom:entry', namespace)\n",
    "    \n",
    "    if entry:\n",
    "        title = entry.find('atom:title', namespace).text\n",
    "        authors = entry.findall('atom:author', namespace)\n",
    "        abstract = entry.find('atom:summary', namespace).text.strip()\n",
    "        date = entry.find('atom:published', namespace).text\n",
    "        date = datetime.strptime(date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d/%m/%Y')\n",
    "        link = entry.find('atom:id', namespace).text\n",
    "\n",
    "        markdown_content += f\"### {title}\\n\\n\"\n",
    "        markdown_content += f\"**Lien de l'article :** [ArXiv]({link})\\n\\n\"\n",
    "        markdown_content += f\"**Date de publication :** {date}\\n\\n\"\n",
    "        markdown_content += \"**Auteur(s) :**\\n\"\n",
    "        for author in authors:\n",
    "            name = author.find('atom:name', namespace).text\n",
    "            markdown_content += f\"- {name}\\n\"\n",
    "        markdown_content += f\"\\n**Résumé :**\\n{abstract}\\n\\n\"\n",
    "        \n",
    "with open(\"test.md\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cryp:\n",
    "    markdown_content = \"## Cryptographie\\n\\n\"\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=id:{i}\"\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    namespace = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('atom:entry', namespace)\n",
    "    \n",
    "    if entry:\n",
    "        title = entry.find('atom:title', namespace).text\n",
    "        authors = entry.findall('atom:author', namespace)\n",
    "        abstract = entry.find('atom:summary', namespace).text.strip()\n",
    "        date = entry.find('atom:published', namespace).text\n",
    "        date = datetime.strptime(date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d/%m/%Y')\n",
    "        link = entry.find('atom:id', namespace).text\n",
    "\n",
    "        markdown_content += f\"### {title}\\n\\n\"\n",
    "        markdown_content += f\"**Lien de l'article :** [ArXiv]({link})\\n\\n\"\n",
    "        markdown_content += f\"**Date de publication :** {date}\\n\\n\"\n",
    "        markdown_content += \"**Auteur(s) :**\\n\"\n",
    "        for author in authors:\n",
    "            name = author.find('atom:name', namespace).text\n",
    "            markdown_content += f\"- {name}\\n\"\n",
    "        markdown_content += f\"\\n**Résumé :**\\n{abstract}\\n\\n\"\n",
    "        \n",
    "with open(\"test.md\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in error:\n",
    "    markdown_content = \"## Caractérisation/suppression des erreurs/bruits\\n\\n\"\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=id:{i}\"\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    namespace = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('atom:entry', namespace)\n",
    "    \n",
    "    if entry:\n",
    "        title = entry.find('atom:title', namespace).text\n",
    "        authors = entry.findall('atom:author', namespace)\n",
    "        abstract = entry.find('atom:summary', namespace).text.strip()\n",
    "        date = entry.find('atom:published', namespace).text\n",
    "        date = datetime.strptime(date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d/%m/%Y')\n",
    "        link = entry.find('atom:id', namespace).text\n",
    "\n",
    "        markdown_content += f\"### {title}\\n\\n\"\n",
    "        markdown_content += f\"**Lien de l'article :** [ArXiv]({link})\\n\\n\"\n",
    "        markdown_content += f\"**Date de publication :** {date}\\n\\n\"\n",
    "        markdown_content += \"**Auteur(s) :**\\n\"\n",
    "        for author in authors:\n",
    "            name = author.find('atom:name', namespace).text\n",
    "            markdown_content += f\"- {name}\\n\"\n",
    "        markdown_content += f\"\\n**Résumé :**\\n{abstract}\\n\\n\"\n",
    "        \n",
    "with open(\"test.md\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in opt:\n",
    "    markdown_content = \"## Algorithme\\n\\n\"\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=id:{i}\"\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    namespace = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('atom:entry', namespace)\n",
    "    \n",
    "    if entry:\n",
    "        title = entry.find('atom:title', namespace).text\n",
    "        authors = entry.findall('atom:author', namespace)\n",
    "        abstract = entry.find('atom:summary', namespace).text.strip()\n",
    "        date = entry.find('atom:published', namespace).text\n",
    "        date = datetime.strptime(date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d/%m/%Y')\n",
    "        link = entry.find('atom:id', namespace).text\n",
    "\n",
    "        markdown_content += f\"### {title}\\n\\n\"\n",
    "        markdown_content += f\"**Lien de l'article :** [ArXiv]({link})\\n\\n\"\n",
    "        markdown_content += f\"**Date de publication :** {date}\\n\\n\"\n",
    "        markdown_content += \"**Auteur(s) :**\\n\"\n",
    "        for author in authors:\n",
    "            name = author.find('atom:name', namespace).text\n",
    "            markdown_content += f\"- {name}\\n\"\n",
    "        markdown_content += f\"\\n**Résumé :**\\n{abstract}\\n\\n\"\n",
    "        \n",
    "with open(\"test.md\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois = [\n",
    "    \"10.1016/j.jocs.2023.102004\",\n",
    "    \"10.1007/978-3-031-36030-5_18\",\n",
    "    \n",
    "]\n",
    "markdown_content = \"# Publications\\n\\n Ici vous retrouverez toutes les publications ayant bénéficié des fonds HQI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dois:\n",
    "    url = f\"https://api.crossref.org/works/{i}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()[\"message\"]\n",
    "        title = data.get(\"title\", [\"\"])[0]\n",
    "        authors = data.get(\"author\", [])\n",
    "        abstract = data.get(\"abstract\", \"\")\n",
    "        date_parts = data.get(\"published-print\", {}).get(\"date-parts\", [[]])[0]\n",
    "        date = f\"{date_parts[2]:02}/{date_parts[1]:02}/{date_parts[0]}\" if len(date_parts) == 3 else \"\"\n",
    "        link = data.get(\"URL\", \"\")\n",
    "\n",
    "        markdown_content += f\"## {title}\\n\\n\" if title else \"\"\n",
    "        markdown_content += f\"**Lien de l'article :** [CrossRef]({link})\\n\\n\" if link else \"\"\n",
    "        markdown_content += f\"**Date de publication :** {date}\\n\\n\" if date else \"\"\n",
    "        \n",
    "        markdown_content += \"**Auteur(s) :**\\n\" + ''.join(f\"- {author.get('given', '')} {author.get('family', '')}\\n\" for author in authors) if authors else \"\"\n",
    "        markdown_content += \"\\n\"\n",
    "\n",
    "        if abstract:\n",
    "            # Utilisation de BeautifulSoup pour nettoyer le résumé\n",
    "            soup = BeautifulSoup(abstract, \"html.parser\")\n",
    "            cleaned_abstract = ''.join(soup.stripped_strings)\n",
    "            markdown_content += f\"**Résumé :**\\n{cleaned_abstract}\\n\\n\"\n",
    "    else:\n",
    "        print(f\"Erreur : {response.status_code}\")\n",
    "\n",
    "with open(\"publicationsDOI.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}